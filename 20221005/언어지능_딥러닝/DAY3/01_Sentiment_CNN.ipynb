{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"1mvcMZjzmoye8_J2LND6mpdAib1aJTh_V","timestamp":1579181395154}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","source":["## 데이터 출처\n","\n","[Naver sentiment movie corpus]: https://github.com/e9t/nsmc/\n","\n","- CNN 모델의 학습을 위해 [Naver sentiment movie corpus] 데이터셋 중 10,000건을 추출하여 사용하였습니다."],"metadata":{"id":"XNAKALrMvlZC"}},{"cell_type":"code","source":["# torchtext.legacy를 사용할 수 있는 torchtext 버전 설치\n","!pip install -U torchtext==0.10.0"],"metadata":{"id":"4xlnVwtmM_0h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664948361323,"user_tz":-540,"elapsed":103940,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"1504e3c3-cc59-4a19-fc76-f833bf5df4d2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 9.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"ay1ouffYd02L","outputId":"239215ab-500a-4574-b20a-eb0d3f0c6e27","executionInfo":{"status":"ok","timestamp":1664948496213,"user_tz":-540,"elapsed":134900,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["#colab 을 이용한 실행시\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"HKiGO6t0dmZx","executionInfo":{"status":"ok","timestamp":1664948496651,"user_tz":-540,"elapsed":458,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"source":["import torch\n","# torch.nn : 신경망 구현을 위한 데이터 구조, 신경망 레이어, 관련함수들이 구현되어 있는 팩키지\n","# torch.nn.functional: torch.nn 팩키지의 함수들이 정의되어 있음 (손실함수, 활성화함수, 풀링함수 등) \n","# torch.autograd : 미분을 위한 함수들이 정의되어 있음\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","\n","# torchtext.legacy : text를 위한 데이터 로더를 제공, 다음과 같은 과정을 편리하게 지원\n","# 토크나이징(Tokenization)\n","# 단어장 생성(Build Vocabulary)\n","# 토큰의 수치화(Numericalize all tokens)\n","# 데이터 로더 생성(Create Data Loader)\n","\n","from torchtext.legacy import data\n","import torchtext.datasets as datasets\n","import pickle"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"5M_ahOAzdmZ3","executionInfo":{"status":"ok","timestamp":1664949237339,"user_tz":-540,"elapsed":503,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"source":["# CNN 모델의 구조와 연산을 정의\n","class CNN_Text(nn.Module):\n","    # 생성자 : 모델의 구조와 동작을 정의\n","    # 객체가 갖는 속성값을 초기화함. 객체가 생성될 때 자동으로 호출된다.\n","    def __init__(self, embed_num, class_num):\n","        super(CNN_Text, self).__init__() # nn.Module 클래스를 초기화\n","        # V: 사전의 크기\n","        # D: embed_dim\n","        # C: 분류하고자 하는 클래스의 개수\n","        # Co : 각 커널(필터)의 갯수\n","        V = embed_num\n","        D = 100 \n","        C = class_num\n","        Co = 50         # output channel 수 (필터의 갯수)\n","        Ks = [2,3,4]\n","\n","        # 사전에 있는 모든 단어 벡터에 random 초기값\n","        self.embed = nn.Embedding(V, D) # 예) 1000*100\n","        # torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride=1)\n","        # convs1에 컨볼루션 모듈의 리스트가 들어감 (필터(커널) 갯수만큼) \n","        # forward에서 순차적으로 접근 가능\n","        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, 100)) for K in Ks])\n","        self.dropout = nn.Dropout(0.2)\n","\n","        # nn.Linear 클래스. Fully Connected Layer \n","        # Applies a linear transformation to the incoming data (y = Wx + b)\n","        # torch.nn.Linear(in_features, out_features)\n","        # in_features: size of each input sample, out_features: size of each output sample \n","        self.fc1 = nn.Linear(len(Ks)*Co, C) # 3(kernel)*50(output)*2(긍정, 부정)\n","\n","        # foward 함수 : 모델이 학습데이터를 입력받아서 forward 연산을 진행\n","        # model 객체를 데이터와 함께 호출하면 자동으로 실행된다.\n","    def forward(self, x):\n","        x = self.embed(x)   # (N, W, D) 미니배치(N), 문장 최대길이, 단어벡터 차원\n","        x = x.unsqueeze(1)  # (N x Ci x W x D) Conv2d를 사용하려면 ** 입력채널 수 추가 **해야 함\n","\n","        # Convolution Layer\n","        # Convolution -> ReLU -> 텐서의 dimension 3을 squeeze(max_pool1d는 3D 입력을 받음)\n","        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]\n","\n","        # Max Pooling\n","        # F.max_pool1d(input, kernel_size): Applies a 1D max pooling over an input\n","        # Tensor.size(dim=None) : Returns the size of the self tensor. If dim is specified, returns the size of that dimension.\n","        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks) max pooling 후에 마지막 차원은 1 -> squeeze\n","        x = torch.cat(x, 1) # torch.cat(tensors, dim), dim=1이면 두번째 차원이 늘어나게 concat (첫번째 차원은 N)\n","        x = self.dropout(x) # (N, len(Ks)*Co), dropout을 적용\n","        logit = self.fc1(x) # fully-connected layer 적용\n","        return logit"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"gM4G8CnWdmZ5","executionInfo":{"status":"ok","timestamp":1664949237339,"user_tz":-540,"elapsed":6,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"source":["class mydataset(data.Dataset):\n","    @staticmethod  # 유틸리티 메소드 정의 시 선언\n","    def sort_key(ex):\n","        return len(ex.text)\n","    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n","        fields = [('text', text_field), ('label', label_field)] # text_field 레이블은 text, label_field 레이블은 label\n","        if examples is None:\n","            path = self.dirname if path is None else path\n","            examples = []\n","            for i,line in enumerate(open(path,'r',encoding='utf-8')):\n","                if i==0:\n","                    continue\n","                line = line.strip().split('\\t')\n","                txt = line[1].split(' ')               \n","                                  \n","                examples += [ data.Example.fromlist( [ txt, line[2]],fields ) ]\n","        super(mydataset, self).__init__(examples, fields, **kwargs)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWexP0_1dmZ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664949995656,"user_tz":-540,"elapsed":465,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"8f1f245f-b54f-4a20-d7ee-be9ce32a3486"},"source":["# Field : 텐서로 변환될 텍스트 데이터타입을 정의 \n","# text_field, label_field : 전처리 관련된 field 객체를 각각 생성 \n","# batch_first : 미니배치 차원을 맨 앞에 둔 텐서를 생성할 것인지\n","# fix_length : 하나의 문장 내 max 토큰수 \n","# sequential : 시퀀스 데이터 여부\n","text_field = data.Field(batch_first = True, fix_length = 20) # dimension 0에 있는 파라미터는 배치 차원이다\n","label_field = data.Field(sequential= False, batch_first = True, unk_token = None) # unk_token을 표현할 스트링\n","\n","train_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_train_tok.txt') # text와 label을 결합을 해서 하나의 객체로 만들어줌\n","\n","test_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_test_tok.txt')\n","#print(test_data.fields.items())\n","\n","# vocab 생성\n","text_field.build_vocab(train_data)\n","label_field.build_vocab(train_data)\n","\n","# Data Loader 생성 (train_data, test_data를 각각 100개, 1개씩 데이터 로딩)\n","train_iter, test_iter = data.Iterator.splits(   # train과 test를 넘겨줘서 iterator를 train 100개 test는 1개로 반복적으로 로딩\n","                            (train_data, test_data), \n","                            batch_sizes=(100, 1))#, device= 'cuda')\n","len(text_field.vocab)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21893"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0lf4fXqhdmZ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664950395903,"user_tz":-540,"elapsed":313,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"1df29ddd-8630-4559-bfca-91764129cc44"},"source":["# CNN모델 객체를 생성 (embed_num, class_num)\n","cnn = CNN_Text(len(text_field.vocab),2)\n","\n","# torch.optim : 신경망 학습을 위한 다양한 파라미터 최적화 알고리즘이 구현되어 있는 팩키지\n","# Optimizer를 설정\n","optimizer = torch.optim.Adam(cnn.parameters())\n","cnn.train() # start할 준비를 끝마침 -> train mode를 시작하겠다 (내부 구조를 찍어서 확인 가능)\n"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN_Text(\n","  (embed): Embedding(21893, 100)\n","  (convs1): ModuleList(\n","    (0): Conv2d(1, 50, kernel_size=(2, 100), stride=(1, 1))\n","    (1): Conv2d(1, 50, kernel_size=(3, 100), stride=(1, 1))\n","    (2): Conv2d(1, 50, kernel_size=(4, 100), stride=(1, 1))\n","  )\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc1): Linear(in_features=150, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# sqeeze(index) => sqeeze index에 3을 주면 3차원으로 줄어든다\n","# 즉 output에 차원을 맞춰주기 위해서 등 사용\n","# unsqeeze는 채널을 하나 추가하기 위해서 차원을 하나 추가하기 위해서\n","# tensor의 형태를 맞추기 위해서 호출하는 함수"],"metadata":{"id":"x9CLcs9fyIUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"lCPi9H_MdmaC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664950730447,"user_tz":-540,"elapsed":111865,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"a997c7bf-8365-4c2f-fe05-8108ff20eefc"},"source":["for epoch in range(20):\n","    \n","    totalloss = 0\n","    for batch in train_iter:\n","        optimizer.zero_grad() # resets the gradient to 0\n","        \n","        txt = batch.text\n","        label = batch.label\n","                \n","        #print(txt.size()) -> torch.Size([100, 20])\n","        pred = cnn(txt)\n","                \n","        #print(pred.size(), label.size()) -> torch.Size([100, 2]) torch.Size([100])\n","        #print(label)\n","        loss = F.cross_entropy(pred, label)\n","        totalloss += loss.data\n","        \n","        loss.backward() # backward 연산\n","        optimizer.step() # 파라미터 업데이트\n","        \n","    print(epoch,'epoch')    \n","    print('loss : {:.3f}'.format(totalloss.numpy()))\n","\n","torch.save(cnn,'/content/gdrive/My Drive/Colab Notebooks/aivle/model/cnn_model.pt')"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0 epoch\n","loss : 1.833\n","1 epoch\n","loss : 1.498\n","2 epoch\n","loss : 1.722\n","3 epoch\n","loss : 1.364\n","4 epoch\n","loss : 1.325\n","5 epoch\n","loss : 1.182\n","6 epoch\n","loss : 1.136\n","7 epoch\n","loss : 1.110\n","8 epoch\n","loss : 1.047\n","9 epoch\n","loss : 1.096\n","10 epoch\n","loss : 0.978\n","11 epoch\n","loss : 1.004\n","12 epoch\n","loss : 0.935\n","13 epoch\n","loss : 1.094\n","14 epoch\n","loss : 0.905\n","15 epoch\n","loss : 0.900\n","16 epoch\n","loss : 0.956\n","17 epoch\n","loss : 0.824\n","18 epoch\n","loss : 0.888\n","19 epoch\n","loss : 0.942\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"32-nf3Je68OE"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUApbakVdmaF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664951924960,"user_tz":-540,"elapsed":281,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"eb357f41-96c1-47a9-8558-9fff8ad8f0bf"},"source":["%%time\n","from sklearn.metrics import classification_report\n","cnn.eval() # 모델을 evaluation mode로 설정. 정규화 기술(dropout 등)을 배제하여 온전한 모델로 평가\n","correct = 0\n","incorrect = 0\n","y_test = []\n","prediction = []\n","\n","for batch in test_iter:\n","    txt = batch.text\n","    label = batch.label\n","    y_test.append(label.data[0]) #  긍/부정\n","\n","    pred = cnn(txt)\n","    _,ans = torch.max(pred,dim=1) # dimension을 기준으로 (최대값, 최대값이 있는 인덱스) 반환 \n","    prediction.append(ans.data[0]) # ans.data[0]: 최대값이 들어있는 인덱스 (0 또는 1) \n","  \n","    if ans.data[0] == label.data[0]:        \n","        correct += 1    \n","    else:\n","        incorrect += 1\n","    \n","print ('correct : ', correct)\n","print ('incorrect : ', incorrect)\n","print(classification_report(torch.tensor(y_test),     # 정답값\n","                            torch.tensor(prediction), # 예측값\n","                            digits=4,                 # 출력할 자리수\n","                            target_names=['negative', 'positive'])) # display names matching the label\n","\n","# Weighted Avg는 클래스의 수치간의 평균 "],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["correct :  78\n","incorrect :  22\n","              precision    recall  f1-score   support\n","\n","    negative     0.8889    0.6400    0.7442        50\n","    positive     0.7188    0.9200    0.8070        50\n","\n","    accuracy                         0.7800       100\n","   macro avg     0.8038    0.7800    0.7756       100\n","weighted avg     0.8038    0.7800    0.7756       100\n","\n","CPU times: user 71.7 ms, sys: 26 µs, total: 71.7 ms\n","Wall time: 72.5 ms\n"]}]},{"cell_type":"code","metadata":{"id":"i045lkYUdmaH"},"source":[],"execution_count":null,"outputs":[]}]}