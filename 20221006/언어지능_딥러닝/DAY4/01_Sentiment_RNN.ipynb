{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"1ZX72JAO-IaAt5fPRKsUVof8JCHxgPaub","timestamp":1579183200965}],"collapsed_sections":[]},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## 데이터 출처\n","\n","[Naver sentiment movie corpus]: https://github.com/e9t/nsmc/\n","\n","- RNN 모델의 학습을 위해 [Naver sentiment movie corpus] 데이터셋 중 10,000건을 추출하여 사용하였습니다."],"metadata":{"id":"Fo92nKutwxk0"}},{"cell_type":"code","source":["# torchtext.legacy를 사용할 수 있는 torchtext 버전 설치\n","!pip install -U torchtext==0.10.0"],"metadata":{"id":"8WSzxoQ4Nd79","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665035043642,"user_tz":-540,"elapsed":126149,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"e76724b7-f688-4747-8585-f3fe547430bb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.4 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.13.1\n","    Uninstalling torchtext-0.13.1:\n","      Successfully uninstalled torchtext-0.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"CSQVQtQVkMpg","outputId":"473c0c80-7ea2-4348-b31c-e6cc590dd574","executionInfo":{"status":"ok","timestamp":1665035096990,"user_tz":-540,"elapsed":53359,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["#colab 을 이용한 실행시\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"DDhMi_j7kI8u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665035098153,"user_tz":-540,"elapsed":1170,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"outputId":"2e535e68-ca4c-4626-a12a-f865c54e3268"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# torchtext.legacy : text의 preprocessing 파이프라인 정의\n","# 1) 토크나이징(Tokenization)\n","# 2) 단어장 생성(Build Vocabulary)\n","# 3) 토큰의 수치화(Numericalize all tokens)\n","# 4) 데이터 로더 생성(Create Data Loader)\n","from torchtext.legacy import data\n","import torchtext.datasets as datasets\n","\n","import pickle\n","print (torch.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu102\n"]}]},{"cell_type":"markdown","source":["#LSTM\n","Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n","\n","nn.LSTM(input_size, hidden_size, num_layers, bidirectional, batch_first):\n","* input_size – The number of expected features in the input x\n","* hidden_size – The number of features in the hidden state h\n","* num_layers – Number of recurrent layers. \n","* bidirectional – If True, becomes a bidirectional LSTM. Default: False\n","* batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Default: False. Note that this does not apply to hidden or cell states."],"metadata":{"id":"_XfGe-AqK1NF"}},{"cell_type":"code","metadata":{"id":"MHVoD2RfkI81","executionInfo":{"status":"ok","timestamp":1665035098154,"user_tz":-540,"elapsed":7,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"source":["class RNN_Text(nn.Module):    \n","    def __init__(self, embed_num, class_num):\n","        # super()로 Base Class의 __init__() 호출 (nn.Module 클래스 생성자 호출)\n","        # super(파생클래스, self).__init__() 파이썬 2.x 문법\n","        # super().__init__() 파이썬 3.x 문법 둘다 사용 가능\n","        super(RNN_Text, self).__init__()\n","        # super().__init__()  \n","        \n","        V = embed_num   # 단어 사전의 크기\n","        C = class_num   # 분류하고자 하는 클래스 개수        \n","        H = 256         # 히든 사이즈\n","        D = 100         # 단어벡터 차원 100        \n","        self.embed = nn.Embedding(V, D)        \n","        \n","        # LSTM Layer, bidirectional이므로 출력되는 벡터의 크기는 H * 2\n","        self.rnn = nn.LSTM(D, H, bidirectional = True)\n","                 \n","        # Linear Layer : (512, 2)\n","        self.out = nn.Linear(H*2, C)\n","        \n","    def forward(self, x):\n","        x = self.embed(x)     # (N, W, D) 문장 x의 단어 벡터값 가져옴\n","      \n","        # LSTM 모듈 실행\n","        # LSTM 입력데이터\n","        # input x : torch.Size([30, 100, 100]) [시퀀스 길이, 배치 사이즈, Dimension]\n","        x,(_,__) = self.rnn( x, ( self.h, self.c ) )  # lstm을 거쳐나온 값을 x에 담기\n","\n","        # output x : torch.Size([30, 100, 512]) [시퀀스 길이, 배치 사이즈, 256 * 2]\n","\n","        # 최종 Hidden Layer로 Linear 모듈 실행   \n","        logit = self.out(x[-1])  # 가장 마지막 t 단계의 sequence차원에 있는 마지막 단어 hidden states들이 linear단계로 전달\n","\n","        # 최종 예측 벡터 크기: [배치 사이즈, C], C: 클래스 개수\n","        return logit       # logit : torch.Size([100, 2])\n","\n","    def inithidden(self, b):\n","        #self.h = Variable(torch.randn(2, b, 256))\n","        #self.c = Variable(torch.randn(2, b, 256))    \n","        self.h = torch.randn(2, b, 256)   # [2, batch_size, 256]\n","        self.c = torch.randn(2, b, 256)   # [2, batch_size, 256]\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuVqEcvNkI83","executionInfo":{"status":"ok","timestamp":1665035098154,"user_tz":-540,"elapsed":6,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"source":["# train, test dataset을 만들어준다\n","class mydataset(data.Dataset):\n","    @staticmethod\n","    def sort_key(ex):\n","        return len(ex.text)\n","    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n","        fields = [('text', text_field), ('label', label_field)]\n","        if examples is None:\n","            path = self.dirname if path is None else path\n","            examples = []\n","            for i,line in enumerate(open(path,'r',encoding='utf-8')):\n","                if i==0:      # 첫번째 라인은 skip\n","                    continue\n","                line = line.strip().split('\\t') # text, label 필드가 /tab으로 구분되어 있다                  \n","                txt = line[1].split(' ')  # 공백을 기준으로 문자열을 나누어 토큰 리스트를 만든다. line[0]에는 ID\n","               \n","                # examples: 학습 텍스트, 라벨 텍스트\n","                # data.Example : Defines a single training or test example.\n","                examples += [ data.Example.fromlist( [txt, line[2]],fields ) ]\n","        # Create a dataset from a list of Examples and Fields.\n","        # fields : field name, field \n","        super(mydataset, self).__init__(examples, fields, **kwargs) \n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"D-YgsUg5kI86","outputId":"39de20dd-cd37-4f47-ada0-a6699b349f4f","executionInfo":{"status":"ok","timestamp":1665035099795,"user_tz":-540,"elapsed":1646,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Field 객체는 다음과 같은 값을 통하여 데이터의 각 필드를 처리하는 방법을 지정\n","# fix_length: A fixed length that all examples using this field will be padded to, or None for flexible sequence lengths. \n","# sequential: Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True.\n","# batch_first: Whether to produce tensors with the batch dimension first. Default: False.\n","##text_field = data.Field(fix_length=20)\n","text_field = data.Field(fix_length=30)\n","label_field = data.Field(sequential=False, batch_first = True, unk_token = None)\n","\n","# 학습데이터 Dataset\n","train_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_train_tok.txt')\n","# 테스트데이터 Dataset\n","test_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_test_tok.txt')\n","\n","text_field.build_vocab(train_data)    # Construct the Vocab object \n","label_field.build_vocab(train_data)   # Construct the Vocab object \n","\n","# Create Iterator objects for train data, test data\n","train_iter, test_iter = data.Iterator.splits(\n","                            (train_data, test_data), \n","                            batch_sizes=(100, 1), repeat=False)#, device = -1)\n","len(text_field.vocab)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21893"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"WPOJtjBWkI88","outputId":"35217e47-1da0-4da2-ae7d-5d49f2513a97","executionInfo":{"status":"ok","timestamp":1665035099796,"user_tz":-540,"elapsed":5,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["rnn = RNN_Text(len(text_field.vocab),2)     # embed_num, class_num\n","optimizer = torch.optim.Adam(rnn.parameters())\n","rnn.train()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNN_Text(\n","  (embed): Embedding(21893, 100)\n","  (rnn): LSTM(100, 256, bidirectional=True)\n","  (out): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"HEGfWoiykI8_","outputId":"1801f154-5182-4d81-da56-691e7787aa5f","executionInfo":{"status":"ok","timestamp":1665035538424,"user_tz":-540,"elapsed":438632,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["%%time\n","bool_debug = True    # 텐서의 차원을 출력할 경우 True로 설정\n","print_idx = 3        # 출력 횟수\n","for epoch in range(10):\n","    \n","    totalloss = 0\n","    for batch in train_iter:\n","        optimizer.zero_grad()\n","        \n","        txt = batch.text        # torch.Size([20, 100])\n","        label = batch.label     # torch.Size([100])\n","        \n","        if bool_debug and print_idx > 0:\n","          print (\"txt.shape:\", txt.shape)\n","          print_idx -= 1\n","\n","        # inithiddend : hidden state, cell state 초기화 함수\n","        rnn.inithidden(txt.size(1))   # 배치 사이즈를 전달\n","        # 학습 실행\n","        pred = rnn(txt)\n","        \n","        if bool_debug and print_idx > 0:\n","          print(\"pred.shape:\", pred.shape)\n","          print(\"label.shape:\", label.shape)\n","          print_idx -= 1        \n","\n","        loss = F.cross_entropy(pred, label)\n","        totalloss += loss.data\n","        \n","        loss.backward()\n","        optimizer.step()\n","        \n","    print(epoch,'epoch')  \n","    print('loss : {:.3f}'.format(totalloss.numpy()))\n","       \n","torch.save(rnn,'/content/gdrive/My Drive/Colab Notebooks/aivle/model/rnn_model.pt')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["txt.shape: torch.Size([30, 100])\n","pred.shape: torch.Size([100, 2])\n","label.shape: torch.Size([100])\n","txt.shape: torch.Size([30, 100])\n","0 epoch\n","loss : 69.748\n","1 epoch\n","loss : 69.157\n","2 epoch\n","loss : 63.637\n","3 epoch\n","loss : 50.839\n","4 epoch\n","loss : 40.270\n","5 epoch\n","loss : 32.229\n","6 epoch\n","loss : 25.666\n","7 epoch\n","loss : 19.634\n","8 epoch\n","loss : 15.693\n","9 epoch\n","loss : 12.990\n","CPU times: user 7min 3s, sys: 9.77 s, total: 7min 13s\n","Wall time: 7min 18s\n"]}]},{"cell_type":"code","metadata":{"id":"ldrqhEt6kI9B","outputId":"14f87e18-ae8e-49fe-a478-61b54078bca4","executionInfo":{"status":"ok","timestamp":1665035540650,"user_tz":-540,"elapsed":2244,"user":{"displayName":"정연수","userId":"02873126808620457795"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["%%time\n","bool_debug = True    # 텐서의 차원을 출력할 경우 True로 설정\n","\n","from sklearn.metrics import classification_report\n","correct = 0\n","incorrect = 0\n","rnn.eval()\n","y_test = []\n","prediction = []\n","\n","# 텐서 차원 확인용\n","print_tensor_shape = 2\n","print_idx = 1\n","\n","for batch in test_iter:\n","    txt = batch.text            # txt.shape: torch.Size([max_sent_len, 1])\n","    label = batch.label         # label.shape: torch.Size([1])\n","    y_test.append(label.data[0])\n","    \n","    rnn.inithidden(txt.size(1))\n","   \n","    pred = rnn(txt)               # pred.shape: torch.Size([1, 2])\n","    \n","    _ , ans = torch.max(pred,dim=1) # ans.shape: torch.Size([1])\n","    prediction.append(ans.data[0])\n","    \n","    \n","    #---------------------------------------\n","    # 텐서 형태, 데이터를 출력\n","    if bool_debug and print_tensor_shape > 0:\n","      print(\"-----\", print_idx, \"-----\") \n","      print(\"prediction:\", prediction)\n","      print(\"y_test:\", y_test)\n","      print(\"pred.shape:\", pred.shape)\n","      #print(\"pred.data[0]:\", pred.data[0])\n","      print(\"pred[0]:\", pred[0])\n","      print(\"pred[0][0]:\", pred[0][0])\n","      print(\"pred[0][1]:\", pred[0][1])\n","      print(\"ans.data[0]:\", ans.data[0])\n","      print(\"ans.shape:\", ans.shape)\n","      print(\"txt.shape:\", txt.shape)\n","      print(\"label.shape:\", label.shape)\n","      print(\"label.data[0]:\", label.data[0])\n","      \n","      print()\n","      print_tensor_shape -= 1\n","      print_idx += 1\n","      #---------------------------------------\n","\n","    if ans.data[0] == label.data[0]:  # ans.data[0]: tensor(0) 또는 tensor(1)\n","        correct += 1    \n","    else:\n","        incorrect += 1\n","    \n","print ('correct : ', correct)\n","print ('incorrect : ', incorrect)\n","print(classification_report(torch.tensor(y_test), \n","                            torch.tensor(prediction), \n","                            digits=4, \n","                            target_names=['negative', 'positive']))\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["----- 1 -----\n","prediction: [tensor(1)]\n","y_test: [tensor(1)]\n","pred.shape: torch.Size([1, 2])\n","pred[0]: tensor([-0.4761,  0.4260], grad_fn=<SelectBackward>)\n","pred[0][0]: tensor(-0.4761, grad_fn=<SelectBackward>)\n","pred[0][1]: tensor(0.4260, grad_fn=<SelectBackward>)\n","ans.data[0]: tensor(1)\n","ans.shape: torch.Size([1])\n","txt.shape: torch.Size([30, 1])\n","label.shape: torch.Size([1])\n","label.data[0]: tensor(1)\n","\n","----- 2 -----\n","prediction: [tensor(1), tensor(1)]\n","y_test: [tensor(1), tensor(1)]\n","pred.shape: torch.Size([1, 2])\n","pred[0]: tensor([-1.0454,  1.1015], grad_fn=<SelectBackward>)\n","pred[0][0]: tensor(-1.0454, grad_fn=<SelectBackward>)\n","pred[0][1]: tensor(1.1015, grad_fn=<SelectBackward>)\n","ans.data[0]: tensor(1)\n","ans.shape: torch.Size([1])\n","txt.shape: torch.Size([30, 1])\n","label.shape: torch.Size([1])\n","label.data[0]: tensor(1)\n","\n","correct :  85\n","incorrect :  15\n","              precision    recall  f1-score   support\n","\n","    negative     0.7966    0.9400    0.8624        50\n","    positive     0.9268    0.7600    0.8352        50\n","\n","    accuracy                         0.8500       100\n","   macro avg     0.8617    0.8500    0.8488       100\n","weighted avg     0.8617    0.8500    0.8488       100\n","\n","CPU times: user 1.55 s, sys: 136 ms, total: 1.69 s\n","Wall time: 2.23 s\n"]}]},{"cell_type":"code","metadata":{"id":"yEWu-5QokI9E","executionInfo":{"status":"ok","timestamp":1665035540651,"user_tz":-540,"elapsed":8,"user":{"displayName":"정연수","userId":"02873126808620457795"}}},"source":[],"execution_count":9,"outputs":[]}]}