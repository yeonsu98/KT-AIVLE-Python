{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYlqKiNaVq30wCi8Qz4W6J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_1Wxsn4RM85X","executionInfo":{"status":"ok","timestamp":1663296685245,"user_tz":-540,"elapsed":694,"user":{"displayName":"정연수","userId":"13922698878900374535"}}},"outputs":[],"source":["from sklearn.datasets import load_wine\n","\n","wine = load_wine()"]},{"cell_type":"code","source":["print(wine.DESCR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXmehxgJNRt4","executionInfo":{"status":"ok","timestamp":1663296688072,"user_tz":-540,"elapsed":26,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"72b82571-c349-4c70-ca98-8cd8e3aacba7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[".. _wine_dataset:\n","\n","Wine recognition dataset\n","------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 178 (50 in each of three classes)\n","    :Number of Attributes: 13 numeric, predictive attributes and the class\n","    :Attribute Information:\n"," \t\t- Alcohol\n"," \t\t- Malic acid\n"," \t\t- Ash\n","\t\t- Alcalinity of ash  \n"," \t\t- Magnesium\n","\t\t- Total phenols\n"," \t\t- Flavanoids\n"," \t\t- Nonflavanoid phenols\n"," \t\t- Proanthocyanins\n","\t\t- Color intensity\n"," \t\t- Hue\n"," \t\t- OD280/OD315 of diluted wines\n"," \t\t- Proline\n","\n","    - class:\n","            - class_0\n","            - class_1\n","            - class_2\n","\t\t\n","    :Summary Statistics:\n","    \n","    ============================= ==== ===== ======= =====\n","                                   Min   Max   Mean     SD\n","    ============================= ==== ===== ======= =====\n","    Alcohol:                      11.0  14.8    13.0   0.8\n","    Malic Acid:                   0.74  5.80    2.34  1.12\n","    Ash:                          1.36  3.23    2.36  0.27\n","    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n","    Magnesium:                    70.0 162.0    99.7  14.3\n","    Total Phenols:                0.98  3.88    2.29  0.63\n","    Flavanoids:                   0.34  5.08    2.03  1.00\n","    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n","    Proanthocyanins:              0.41  3.58    1.59  0.57\n","    Colour Intensity:              1.3  13.0     5.1   2.3\n","    Hue:                          0.48  1.71    0.96  0.23\n","    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n","    Proline:                       278  1680     746   315\n","    ============================= ==== ===== ======= =====\n","\n","    :Missing Attribute Values: None\n","    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n","    :Creator: R.A. Fisher\n","    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n","    :Date: July, 1988\n","\n","This is a copy of UCI ML Wine recognition datasets.\n","https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n","\n","The data is the results of a chemical analysis of wines grown in the same\n","region in Italy by three different cultivators. There are thirteen different\n","measurements taken for different constituents found in the three types of\n","wine.\n","\n","Original Owners: \n","\n","Forina, M. et al, PARVUS - \n","An Extendible Package for Data Exploration, Classification and Correlation. \n","Institute of Pharmaceutical and Food Analysis and Technologies,\n","Via Brigata Salerno, 16147 Genoa, Italy.\n","\n","Citation:\n","\n","Lichman, M. (2013). UCI Machine Learning Repository\n","[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n","School of Information and Computer Science. \n","\n",".. topic:: References\n","\n","  (1) S. Aeberhard, D. Coomans and O. de Vel, \n","  Comparison of Classifiers in High Dimensional Settings, \n","  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n","  Mathematics and Statistics, James Cook University of North Queensland. \n","  (Also submitted to Technometrics). \n","\n","  The data was used with many others for comparing various \n","  classifiers. The classes are separable, though only RDA \n","  has achieved 100% correct classification. \n","  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n","  (All results using the leave-one-out technique) \n","\n","  (2) S. Aeberhard, D. Coomans and O. de Vel, \n","  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n","  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n","  Mathematics and Statistics, James Cook University of North Queensland. \n","  (Also submitted to Journal of Chemometrics).\n","\n"]}]},{"cell_type":"code","source":["x = wine.data\n","y = wine.target"],"metadata":{"id":"b7-btZ5kNURA","executionInfo":{"status":"ok","timestamp":1663296703435,"user_tz":-540,"elapsed":8,"user":{"displayName":"정연수","userId":"13922698878900374535"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["x.shape, y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76algRzZNsLG","executionInfo":{"status":"ok","timestamp":1663296791970,"user_tz":-540,"elapsed":21,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"cd9771f0-d8a4-402b-f536-50d3e2bacd90"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((178, 13), (178,))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import pandas as pd\n","\n","pd.DataFrame(x, columns=wine.feature_names).describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"W59irzbZN6BZ","executionInfo":{"status":"ok","timestamp":1663296939540,"user_tz":-540,"elapsed":9,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"0fe0fa95-062f-4694-dd2e-9570509dee74"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n","count  178.000000  178.000000  178.000000         178.000000  178.000000   \n","mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n","std      0.811827    1.117146    0.274344           3.339564   14.282484   \n","min     11.030000    0.740000    1.360000          10.600000   70.000000   \n","25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n","50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n","75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n","max     14.830000    5.800000    3.230000          30.000000  162.000000   \n","\n","       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n","count     178.000000  178.000000            178.000000       178.000000   \n","mean        2.295112    2.029270              0.361854         1.590899   \n","std         0.625851    0.998859              0.124453         0.572359   \n","min         0.980000    0.340000              0.130000         0.410000   \n","25%         1.742500    1.205000              0.270000         1.250000   \n","50%         2.355000    2.135000              0.340000         1.555000   \n","75%         2.800000    2.875000              0.437500         1.950000   \n","max         3.880000    5.080000              0.660000         3.580000   \n","\n","       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n","count       178.000000  178.000000                    178.000000   178.000000  \n","mean          5.058090    0.957449                      2.611685   746.893258  \n","std           2.318286    0.228572                      0.709990   314.907474  \n","min           1.280000    0.480000                      1.270000   278.000000  \n","25%           3.220000    0.782500                      1.937500   500.500000  \n","50%           4.690000    0.965000                      2.780000   673.500000  \n","75%           6.200000    1.120000                      3.170000   985.000000  \n","max          13.000000    1.710000                      4.000000  1680.000000  "],"text/html":["\n","  <div id=\"df-227cf165-f774-4149-a828-9375b31fda2f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alcohol</th>\n","      <th>malic_acid</th>\n","      <th>ash</th>\n","      <th>alcalinity_of_ash</th>\n","      <th>magnesium</th>\n","      <th>total_phenols</th>\n","      <th>flavanoids</th>\n","      <th>nonflavanoid_phenols</th>\n","      <th>proanthocyanins</th>\n","      <th>color_intensity</th>\n","      <th>hue</th>\n","      <th>od280/od315_of_diluted_wines</th>\n","      <th>proline</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>13.000618</td>\n","      <td>2.336348</td>\n","      <td>2.366517</td>\n","      <td>19.494944</td>\n","      <td>99.741573</td>\n","      <td>2.295112</td>\n","      <td>2.029270</td>\n","      <td>0.361854</td>\n","      <td>1.590899</td>\n","      <td>5.058090</td>\n","      <td>0.957449</td>\n","      <td>2.611685</td>\n","      <td>746.893258</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.811827</td>\n","      <td>1.117146</td>\n","      <td>0.274344</td>\n","      <td>3.339564</td>\n","      <td>14.282484</td>\n","      <td>0.625851</td>\n","      <td>0.998859</td>\n","      <td>0.124453</td>\n","      <td>0.572359</td>\n","      <td>2.318286</td>\n","      <td>0.228572</td>\n","      <td>0.709990</td>\n","      <td>314.907474</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>11.030000</td>\n","      <td>0.740000</td>\n","      <td>1.360000</td>\n","      <td>10.600000</td>\n","      <td>70.000000</td>\n","      <td>0.980000</td>\n","      <td>0.340000</td>\n","      <td>0.130000</td>\n","      <td>0.410000</td>\n","      <td>1.280000</td>\n","      <td>0.480000</td>\n","      <td>1.270000</td>\n","      <td>278.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>12.362500</td>\n","      <td>1.602500</td>\n","      <td>2.210000</td>\n","      <td>17.200000</td>\n","      <td>88.000000</td>\n","      <td>1.742500</td>\n","      <td>1.205000</td>\n","      <td>0.270000</td>\n","      <td>1.250000</td>\n","      <td>3.220000</td>\n","      <td>0.782500</td>\n","      <td>1.937500</td>\n","      <td>500.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>13.050000</td>\n","      <td>1.865000</td>\n","      <td>2.360000</td>\n","      <td>19.500000</td>\n","      <td>98.000000</td>\n","      <td>2.355000</td>\n","      <td>2.135000</td>\n","      <td>0.340000</td>\n","      <td>1.555000</td>\n","      <td>4.690000</td>\n","      <td>0.965000</td>\n","      <td>2.780000</td>\n","      <td>673.500000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>13.677500</td>\n","      <td>3.082500</td>\n","      <td>2.557500</td>\n","      <td>21.500000</td>\n","      <td>107.000000</td>\n","      <td>2.800000</td>\n","      <td>2.875000</td>\n","      <td>0.437500</td>\n","      <td>1.950000</td>\n","      <td>6.200000</td>\n","      <td>1.120000</td>\n","      <td>3.170000</td>\n","      <td>985.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>14.830000</td>\n","      <td>5.800000</td>\n","      <td>3.230000</td>\n","      <td>30.000000</td>\n","      <td>162.000000</td>\n","      <td>3.880000</td>\n","      <td>5.080000</td>\n","      <td>0.660000</td>\n","      <td>3.580000</td>\n","      <td>13.000000</td>\n","      <td>1.710000</td>\n","      <td>4.000000</td>\n","      <td>1680.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-227cf165-f774-4149-a828-9375b31fda2f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-227cf165-f774-4149-a828-9375b31fda2f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-227cf165-f774-4149-a828-9375b31fda2f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["wine.target_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rI7pAW9O--C","executionInfo":{"status":"ok","timestamp":1663297178236,"user_tz":-540,"elapsed":8,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"38effa72-28ed-483f-e8a2-d8793c739652"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['class_0', 'class_1', 'class_2'], dtype='<U7')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# 1. 전처리\n","# 1) train/test split\n","from sklearn.model_selection import train_test_split\n","\n","train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=2022)\n","\n","# 2) scaling\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","train_x = scaler.fit_transform(train_x)\n","test_x = scaler.transform(test_x)\n","\n","# 3. one-hot encoding\n","from tensorflow.keras.utils import to_categorical\n","\n","len_y = len(set(train_y))\n","train_y = to_categorical(train_y, len_y)\n","test_y = to_categorical(test_y, len_y)"],"metadata":{"id":"sZjygtDhNYbs","executionInfo":{"status":"ok","timestamp":1663297274119,"user_tz":-540,"elapsed":6,"user":{"displayName":"정연수","userId":"13922698878900374535"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train_y.shape, test_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPYCPqw6Plqk","executionInfo":{"status":"ok","timestamp":1663297291619,"user_tz":-540,"elapsed":596,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"37fa7600-4d16-40a2-a403-f9724215840c"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((142, 3), (36, 3))"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# 2. 모델링\n","from tensorflow import keras\n","\n","# 1) 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2) 레이어 생성\n","il = keras.layers.Input(shape=(13,))\n","ol = keras.layers.Dense(3, activation='softmax')(il)\n","\n","# 3) 모델 생성\n","model = keras.models.Model(il, ol)\n","\n","# 4) 모델 컴파일\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","# 5) 모델 요약\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XX48FJpAOj08","executionInfo":{"status":"ok","timestamp":1663297839200,"user_tz":-540,"elapsed":453,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"820052be-7fde-4462-e972-dac287473b0f"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 13)]              0         \n","                                                                 \n"," dense (Dense)               (None, 3)                 42        \n","                                                                 \n","=================================================================\n","Total params: 42\n","Trainable params: 42\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# 3. 모델 학습\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0,\n","                   patience=5,\n","                   verbose=1,\n","                   restore_best_weights=True)\n","\n","model.fit(train_x, train_y, epochs=100, validation_split=0.1, callbacks=[es], verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Hec0xSHOxLO","executionInfo":{"status":"ok","timestamp":1663297844686,"user_tz":-540,"elapsed":5063,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"f8344301-7f12-46cb-8904-71a0d143af20"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","4/4 [==============================] - 1s 53ms/step - loss: 1.1354 - accuracy: 0.4173 - val_loss: 1.0833 - val_accuracy: 0.4667\n","Epoch 2/100\n","4/4 [==============================] - 0s 9ms/step - loss: 1.1297 - accuracy: 0.4252 - val_loss: 1.0785 - val_accuracy: 0.4667\n","Epoch 3/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.1243 - accuracy: 0.4409 - val_loss: 1.0738 - val_accuracy: 0.4667\n","Epoch 4/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.1187 - accuracy: 0.4252 - val_loss: 1.0688 - val_accuracy: 0.4667\n","Epoch 5/100\n","4/4 [==============================] - 0s 12ms/step - loss: 1.1136 - accuracy: 0.4252 - val_loss: 1.0643 - val_accuracy: 0.4667\n","Epoch 6/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.1081 - accuracy: 0.4252 - val_loss: 1.0596 - val_accuracy: 0.5333\n","Epoch 7/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.1028 - accuracy: 0.4331 - val_loss: 1.0549 - val_accuracy: 0.5333\n","Epoch 8/100\n","4/4 [==============================] - 0s 12ms/step - loss: 1.0977 - accuracy: 0.4488 - val_loss: 1.0502 - val_accuracy: 0.5333\n","Epoch 9/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0926 - accuracy: 0.4488 - val_loss: 1.0456 - val_accuracy: 0.5333\n","Epoch 10/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0875 - accuracy: 0.4488 - val_loss: 1.0410 - val_accuracy: 0.5333\n","Epoch 11/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0826 - accuracy: 0.4488 - val_loss: 1.0364 - val_accuracy: 0.5333\n","Epoch 12/100\n","4/4 [==============================] - 0s 17ms/step - loss: 1.0778 - accuracy: 0.4488 - val_loss: 1.0321 - val_accuracy: 0.5333\n","Epoch 13/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0729 - accuracy: 0.4567 - val_loss: 1.0278 - val_accuracy: 0.5333\n","Epoch 14/100\n","4/4 [==============================] - 0s 12ms/step - loss: 1.0682 - accuracy: 0.4567 - val_loss: 1.0235 - val_accuracy: 0.5333\n","Epoch 15/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0632 - accuracy: 0.4646 - val_loss: 1.0189 - val_accuracy: 0.5333\n","Epoch 16/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0585 - accuracy: 0.4882 - val_loss: 1.0142 - val_accuracy: 0.5333\n","Epoch 17/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0539 - accuracy: 0.4882 - val_loss: 1.0101 - val_accuracy: 0.5333\n","Epoch 18/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0492 - accuracy: 0.4961 - val_loss: 1.0058 - val_accuracy: 0.5333\n","Epoch 19/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0446 - accuracy: 0.5039 - val_loss: 1.0012 - val_accuracy: 0.5333\n","Epoch 20/100\n","4/4 [==============================] - 0s 11ms/step - loss: 1.0400 - accuracy: 0.5118 - val_loss: 0.9970 - val_accuracy: 0.5333\n","Epoch 21/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0353 - accuracy: 0.5197 - val_loss: 0.9927 - val_accuracy: 0.6000\n","Epoch 22/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0308 - accuracy: 0.5197 - val_loss: 0.9886 - val_accuracy: 0.6000\n","Epoch 23/100\n","4/4 [==============================] - 0s 11ms/step - loss: 1.0265 - accuracy: 0.5197 - val_loss: 0.9844 - val_accuracy: 0.6000\n","Epoch 24/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0222 - accuracy: 0.5197 - val_loss: 0.9805 - val_accuracy: 0.6000\n","Epoch 25/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0177 - accuracy: 0.5197 - val_loss: 0.9763 - val_accuracy: 0.6000\n","Epoch 26/100\n","4/4 [==============================] - 0s 11ms/step - loss: 1.0133 - accuracy: 0.5197 - val_loss: 0.9720 - val_accuracy: 0.6000\n","Epoch 27/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.5276 - val_loss: 0.9679 - val_accuracy: 0.6000\n","Epoch 28/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0047 - accuracy: 0.5354 - val_loss: 0.9640 - val_accuracy: 0.6000\n","Epoch 29/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0002 - accuracy: 0.5354 - val_loss: 0.9599 - val_accuracy: 0.6000\n","Epoch 30/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9958 - accuracy: 0.5354 - val_loss: 0.9555 - val_accuracy: 0.6000\n","Epoch 31/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.9917 - accuracy: 0.5354 - val_loss: 0.9515 - val_accuracy: 0.6000\n","Epoch 32/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9874 - accuracy: 0.5354 - val_loss: 0.9476 - val_accuracy: 0.6000\n","Epoch 33/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9831 - accuracy: 0.5512 - val_loss: 0.9436 - val_accuracy: 0.6667\n","Epoch 34/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9792 - accuracy: 0.5669 - val_loss: 0.9397 - val_accuracy: 0.6667\n","Epoch 35/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9748 - accuracy: 0.5748 - val_loss: 0.9355 - val_accuracy: 0.6667\n","Epoch 36/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9707 - accuracy: 0.5748 - val_loss: 0.9313 - val_accuracy: 0.6667\n","Epoch 37/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9667 - accuracy: 0.5748 - val_loss: 0.9274 - val_accuracy: 0.6667\n","Epoch 38/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9623 - accuracy: 0.5827 - val_loss: 0.9236 - val_accuracy: 0.6667\n","Epoch 39/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9583 - accuracy: 0.5827 - val_loss: 0.9197 - val_accuracy: 0.6667\n","Epoch 40/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9543 - accuracy: 0.5827 - val_loss: 0.9159 - val_accuracy: 0.6667\n","Epoch 41/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9503 - accuracy: 0.5827 - val_loss: 0.9121 - val_accuracy: 0.6667\n","Epoch 42/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9463 - accuracy: 0.5827 - val_loss: 0.9083 - val_accuracy: 0.6667\n","Epoch 43/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9424 - accuracy: 0.5906 - val_loss: 0.9044 - val_accuracy: 0.6667\n","Epoch 44/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9384 - accuracy: 0.5906 - val_loss: 0.9006 - val_accuracy: 0.6667\n","Epoch 45/100\n","4/4 [==============================] - 0s 20ms/step - loss: 0.9345 - accuracy: 0.5984 - val_loss: 0.8968 - val_accuracy: 0.6667\n","Epoch 46/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9305 - accuracy: 0.6142 - val_loss: 0.8929 - val_accuracy: 0.6667\n","Epoch 47/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9267 - accuracy: 0.6220 - val_loss: 0.8893 - val_accuracy: 0.6667\n","Epoch 48/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9227 - accuracy: 0.6220 - val_loss: 0.8854 - val_accuracy: 0.6667\n","Epoch 49/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9192 - accuracy: 0.6378 - val_loss: 0.8816 - val_accuracy: 0.6667\n","Epoch 50/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.9151 - accuracy: 0.6457 - val_loss: 0.8780 - val_accuracy: 0.6667\n","Epoch 51/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9113 - accuracy: 0.6535 - val_loss: 0.8743 - val_accuracy: 0.6667\n","Epoch 52/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.9075 - accuracy: 0.6614 - val_loss: 0.8709 - val_accuracy: 0.6667\n","Epoch 53/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9039 - accuracy: 0.6614 - val_loss: 0.8674 - val_accuracy: 0.6667\n","Epoch 54/100\n","4/4 [==============================] - 0s 14ms/step - loss: 0.9001 - accuracy: 0.6614 - val_loss: 0.8638 - val_accuracy: 0.6667\n","Epoch 55/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8965 - accuracy: 0.6693 - val_loss: 0.8601 - val_accuracy: 0.6667\n","Epoch 56/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8927 - accuracy: 0.6693 - val_loss: 0.8566 - val_accuracy: 0.6667\n","Epoch 57/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8891 - accuracy: 0.6693 - val_loss: 0.8529 - val_accuracy: 0.6667\n","Epoch 58/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8854 - accuracy: 0.6850 - val_loss: 0.8495 - val_accuracy: 0.6667\n","Epoch 59/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8819 - accuracy: 0.6929 - val_loss: 0.8460 - val_accuracy: 0.6667\n","Epoch 60/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8783 - accuracy: 0.7165 - val_loss: 0.8427 - val_accuracy: 0.7333\n","Epoch 61/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8748 - accuracy: 0.7244 - val_loss: 0.8392 - val_accuracy: 0.7333\n","Epoch 62/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8712 - accuracy: 0.7402 - val_loss: 0.8358 - val_accuracy: 0.7333\n","Epoch 63/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8676 - accuracy: 0.7559 - val_loss: 0.8323 - val_accuracy: 0.7333\n","Epoch 64/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8641 - accuracy: 0.7638 - val_loss: 0.8290 - val_accuracy: 0.7333\n","Epoch 65/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8606 - accuracy: 0.7638 - val_loss: 0.8257 - val_accuracy: 0.7333\n","Epoch 66/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8572 - accuracy: 0.7717 - val_loss: 0.8226 - val_accuracy: 0.7333\n","Epoch 67/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8537 - accuracy: 0.7717 - val_loss: 0.8192 - val_accuracy: 0.7333\n","Epoch 68/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8502 - accuracy: 0.7874 - val_loss: 0.8160 - val_accuracy: 0.7333\n","Epoch 69/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8469 - accuracy: 0.7874 - val_loss: 0.8128 - val_accuracy: 0.7333\n","Epoch 70/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8434 - accuracy: 0.7953 - val_loss: 0.8094 - val_accuracy: 0.7333\n","Epoch 71/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8400 - accuracy: 0.7953 - val_loss: 0.8061 - val_accuracy: 0.7333\n","Epoch 72/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8368 - accuracy: 0.8031 - val_loss: 0.8030 - val_accuracy: 0.7333\n","Epoch 73/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8333 - accuracy: 0.8031 - val_loss: 0.7995 - val_accuracy: 0.7333\n","Epoch 74/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8301 - accuracy: 0.8031 - val_loss: 0.7961 - val_accuracy: 0.7333\n","Epoch 75/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8268 - accuracy: 0.8110 - val_loss: 0.7929 - val_accuracy: 0.7333\n","Epoch 76/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8234 - accuracy: 0.8110 - val_loss: 0.7898 - val_accuracy: 0.7333\n","Epoch 77/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8202 - accuracy: 0.8110 - val_loss: 0.7866 - val_accuracy: 0.7333\n","Epoch 78/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8169 - accuracy: 0.8189 - val_loss: 0.7836 - val_accuracy: 0.7333\n","Epoch 79/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8136 - accuracy: 0.8189 - val_loss: 0.7804 - val_accuracy: 0.8000\n","Epoch 80/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.8105 - accuracy: 0.8189 - val_loss: 0.7772 - val_accuracy: 0.8000\n","Epoch 81/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.8072 - accuracy: 0.8189 - val_loss: 0.7741 - val_accuracy: 0.8000\n","Epoch 82/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8041 - accuracy: 0.8268 - val_loss: 0.7710 - val_accuracy: 0.8000\n","Epoch 83/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8009 - accuracy: 0.8268 - val_loss: 0.7677 - val_accuracy: 0.8000\n","Epoch 84/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7978 - accuracy: 0.8268 - val_loss: 0.7648 - val_accuracy: 0.8000\n","Epoch 85/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.7946 - accuracy: 0.8268 - val_loss: 0.7618 - val_accuracy: 0.8000\n","Epoch 86/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7916 - accuracy: 0.8268 - val_loss: 0.7585 - val_accuracy: 0.8000\n","Epoch 87/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7884 - accuracy: 0.8268 - val_loss: 0.7558 - val_accuracy: 0.8000\n","Epoch 88/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.7854 - accuracy: 0.8268 - val_loss: 0.7530 - val_accuracy: 0.8000\n","Epoch 89/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7823 - accuracy: 0.8346 - val_loss: 0.7499 - val_accuracy: 0.8000\n","Epoch 90/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7792 - accuracy: 0.8504 - val_loss: 0.7469 - val_accuracy: 0.8000\n","Epoch 91/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7762 - accuracy: 0.8504 - val_loss: 0.7439 - val_accuracy: 0.8000\n","Epoch 92/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7733 - accuracy: 0.8583 - val_loss: 0.7410 - val_accuracy: 0.8000\n","Epoch 93/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.7702 - accuracy: 0.8661 - val_loss: 0.7381 - val_accuracy: 0.8000\n","Epoch 94/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7673 - accuracy: 0.8661 - val_loss: 0.7351 - val_accuracy: 0.8000\n","Epoch 95/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.7644 - accuracy: 0.8740 - val_loss: 0.7321 - val_accuracy: 0.8000\n","Epoch 96/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7614 - accuracy: 0.8740 - val_loss: 0.7294 - val_accuracy: 0.8000\n","Epoch 97/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.7585 - accuracy: 0.8740 - val_loss: 0.7267 - val_accuracy: 0.8000\n","Epoch 98/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7556 - accuracy: 0.8740 - val_loss: 0.7241 - val_accuracy: 0.8000\n","Epoch 99/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7527 - accuracy: 0.8740 - val_loss: 0.7213 - val_accuracy: 0.8000\n","Epoch 100/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.7498 - accuracy: 0.8740 - val_loss: 0.7185 - val_accuracy: 0.8000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fab6b1b0650>"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","y_pred = model.predict(test_x)\n","accuracy_score(y_pred.argmax(axis=1), test_y.argmax(axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdeczTmcRssw","executionInfo":{"status":"ok","timestamp":1663297845240,"user_tz":-540,"elapsed":592,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"ae7767d8-228c-49de-ccf5-461fc77c18bb"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8611111111111112"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# 2. 모델링 (히든레이어 있는 버전)\n","from tensorflow import keras\n","\n","# 1) 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2) 레이어 생성\n","il = keras.layers.Input(shape=(13,))\n","h1 = keras.layers.Dense(64, activation='relu')(il)\n","h2 = keras.layers.Dense(64, activation='relu')(h1)\n","ol = keras.layers.Dense(3, activation='softmax')(h2)\n","\n","# 3) 모델 생성\n","model = keras.models.Model(il, ol)\n","\n","# 4) 모델 컴파일\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","# 5) 모델 요약\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvbxMAIBQTDJ","executionInfo":{"status":"ok","timestamp":1663297809503,"user_tz":-540,"elapsed":464,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"ab4799b9-7213-497b-df2f-e033a9c67e3f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 13)]              0         \n","                                                                 \n"," dense (Dense)               (None, 64)                896       \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dense_2 (Dense)             (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 5,251\n","Trainable params: 5,251\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# 3. 모델 학습\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0,\n","                   patience=5,\n","                   verbose=1,\n","                   restore_best_weights=True)\n","\n","model.fit(train_x, train_y, epochs=100, validation_split=0.1, callbacks=[es], verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LW7-NdlkQkca","executionInfo":{"status":"ok","timestamp":1663297815043,"user_tz":-540,"elapsed":5110,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"11945ca5-96cd-45b8-8276-d62442a5d995"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","4/4 [==============================] - 1s 56ms/step - loss: 1.0763 - accuracy: 0.4724 - val_loss: 1.0330 - val_accuracy: 0.6667\n","Epoch 2/100\n","4/4 [==============================] - 0s 10ms/step - loss: 1.0220 - accuracy: 0.6850 - val_loss: 0.9750 - val_accuracy: 0.8000\n","Epoch 3/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.9711 - accuracy: 0.7244 - val_loss: 0.9255 - val_accuracy: 0.8667\n","Epoch 4/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.9245 - accuracy: 0.7874 - val_loss: 0.8784 - val_accuracy: 0.9333\n","Epoch 5/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.8785 - accuracy: 0.8268 - val_loss: 0.8306 - val_accuracy: 0.9333\n","Epoch 6/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.8315 - accuracy: 0.8740 - val_loss: 0.7838 - val_accuracy: 1.0000\n","Epoch 7/100\n","4/4 [==============================] - 0s 14ms/step - loss: 0.7836 - accuracy: 0.9291 - val_loss: 0.7373 - val_accuracy: 1.0000\n","Epoch 8/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.7371 - accuracy: 0.9291 - val_loss: 0.6950 - val_accuracy: 1.0000\n","Epoch 9/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.6868 - accuracy: 0.9449 - val_loss: 0.6421 - val_accuracy: 1.0000\n","Epoch 10/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.6373 - accuracy: 0.9370 - val_loss: 0.5908 - val_accuracy: 1.0000\n","Epoch 11/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.5894 - accuracy: 0.9370 - val_loss: 0.5427 - val_accuracy: 1.0000\n","Epoch 12/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.5393 - accuracy: 0.9370 - val_loss: 0.4956 - val_accuracy: 1.0000\n","Epoch 13/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.4946 - accuracy: 0.9449 - val_loss: 0.4490 - val_accuracy: 1.0000\n","Epoch 14/100\n","4/4 [==============================] - 0s 14ms/step - loss: 0.4509 - accuracy: 0.9528 - val_loss: 0.4045 - val_accuracy: 1.0000\n","Epoch 15/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.4119 - accuracy: 0.9528 - val_loss: 0.3685 - val_accuracy: 1.0000\n","Epoch 16/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.3757 - accuracy: 0.9528 - val_loss: 0.3279 - val_accuracy: 1.0000\n","Epoch 17/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.3413 - accuracy: 0.9528 - val_loss: 0.2890 - val_accuracy: 1.0000\n","Epoch 18/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.3116 - accuracy: 0.9606 - val_loss: 0.2561 - val_accuracy: 1.0000\n","Epoch 19/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.2850 - accuracy: 0.9606 - val_loss: 0.2269 - val_accuracy: 1.0000\n","Epoch 20/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.2611 - accuracy: 0.9606 - val_loss: 0.2024 - val_accuracy: 1.0000\n","Epoch 21/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.2409 - accuracy: 0.9606 - val_loss: 0.1851 - val_accuracy: 1.0000\n","Epoch 22/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.2223 - accuracy: 0.9685 - val_loss: 0.1625 - val_accuracy: 1.0000\n","Epoch 23/100\n","4/4 [==============================] - 0s 18ms/step - loss: 0.2052 - accuracy: 0.9685 - val_loss: 0.1452 - val_accuracy: 1.0000\n","Epoch 24/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1905 - accuracy: 0.9685 - val_loss: 0.1326 - val_accuracy: 1.0000\n","Epoch 25/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1780 - accuracy: 0.9685 - val_loss: 0.1177 - val_accuracy: 1.0000\n","Epoch 26/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.1669 - accuracy: 0.9685 - val_loss: 0.1053 - val_accuracy: 1.0000\n","Epoch 27/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1560 - accuracy: 0.9685 - val_loss: 0.0994 - val_accuracy: 1.0000\n","Epoch 28/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1468 - accuracy: 0.9685 - val_loss: 0.0889 - val_accuracy: 1.0000\n","Epoch 29/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1382 - accuracy: 0.9685 - val_loss: 0.0801 - val_accuracy: 1.0000\n","Epoch 30/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.1309 - accuracy: 0.9685 - val_loss: 0.0757 - val_accuracy: 1.0000\n","Epoch 31/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1237 - accuracy: 0.9685 - val_loss: 0.0694 - val_accuracy: 1.0000\n","Epoch 32/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1167 - accuracy: 0.9764 - val_loss: 0.0613 - val_accuracy: 1.0000\n","Epoch 33/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.1112 - accuracy: 0.9764 - val_loss: 0.0574 - val_accuracy: 1.0000\n","Epoch 34/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.1051 - accuracy: 0.9921 - val_loss: 0.0521 - val_accuracy: 1.0000\n","Epoch 35/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.1011 - accuracy: 0.9921 - val_loss: 0.0479 - val_accuracy: 1.0000\n","Epoch 36/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.0957 - accuracy: 0.9921 - val_loss: 0.0471 - val_accuracy: 1.0000\n","Epoch 37/100\n","4/4 [==============================] - 0s 14ms/step - loss: 0.0911 - accuracy: 0.9921 - val_loss: 0.0445 - val_accuracy: 1.0000\n","Epoch 38/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0869 - accuracy: 0.9921 - val_loss: 0.0405 - val_accuracy: 1.0000\n","Epoch 39/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9921 - val_loss: 0.0381 - val_accuracy: 1.0000\n","Epoch 40/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.9921 - val_loss: 0.0349 - val_accuracy: 1.0000\n","Epoch 41/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9921 - val_loss: 0.0326 - val_accuracy: 1.0000\n","Epoch 42/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0731 - accuracy: 0.9921 - val_loss: 0.0324 - val_accuracy: 1.0000\n","Epoch 43/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0693 - accuracy: 0.9921 - val_loss: 0.0293 - val_accuracy: 1.0000\n","Epoch 44/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.9921 - val_loss: 0.0278 - val_accuracy: 1.0000\n","Epoch 45/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.0632 - accuracy: 0.9921 - val_loss: 0.0259 - val_accuracy: 1.0000\n","Epoch 46/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0608 - accuracy: 0.9921 - val_loss: 0.0248 - val_accuracy: 1.0000\n","Epoch 47/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9921 - val_loss: 0.0243 - val_accuracy: 1.0000\n","Epoch 48/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9921 - val_loss: 0.0233 - val_accuracy: 1.0000\n","Epoch 49/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 0.9921 - val_loss: 0.0224 - val_accuracy: 1.0000\n","Epoch 50/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n","Epoch 51/100\n","4/4 [==============================] - 0s 17ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n","Epoch 52/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n","Epoch 53/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n","Epoch 54/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n","Epoch 55/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n","Epoch 56/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n","Epoch 57/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n","Epoch 58/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n","Epoch 59/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n","Epoch 60/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n","Epoch 61/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n","Epoch 62/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n","Epoch 63/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n","Epoch 64/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n","Epoch 65/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n","Epoch 66/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n","Epoch 67/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n","Epoch 68/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n","Epoch 69/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n","Epoch 70/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n","Epoch 71/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n","Epoch 72/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n","Epoch 73/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n","Epoch 74/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n","Epoch 75/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n","Epoch 76/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n","Epoch 77/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n","Epoch 78/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n","Epoch 79/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n","Epoch 80/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n","Epoch 81/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n","Epoch 82/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n","Epoch 83/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n","Epoch 84/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n","Epoch 85/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n","Epoch 86/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n","Epoch 87/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n","Epoch 88/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n","Epoch 89/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n","Epoch 90/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n","Epoch 91/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n","Epoch 92/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n","Epoch 93/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n","Epoch 94/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 95/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 96/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n","Epoch 97/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 98/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 99/100\n","4/4 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n","Epoch 100/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fab6b1cf050>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","y_pred = model.predict(test_x)\n","accuracy_score(y_pred.argmax(axis=1), test_y.argmax(axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7BsfTMGQnF4","executionInfo":{"status":"ok","timestamp":1663297792077,"user_tz":-540,"elapsed":442,"user":{"displayName":"정연수","userId":"13922698878900374535"}},"outputId":"146b9441-9efc-4577-dd76-9202ae58d480"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[],"metadata":{"id":"zm69w87zQ-D7"},"execution_count":null,"outputs":[]}]}